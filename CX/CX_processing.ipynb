{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd118733-c97b-4696-b38b-27dfa3349288",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91980d1d-ecf2-454e-904f-902fffa341a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f73954a-2345-44bc-a7b4-5765358fc215",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"curious-skyline-360213\"\n",
    "dataset_id = \"CX\"\n",
    "pipeline_root_path = \"gs://curious-skyline/Projects/CX/CXpipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63eb321a-348a-474e-8b92-6b1b28ea5612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "bq_client = bigquery.Client(location=\"us-west1\", project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e3cdce7-c9de-4263-a4f5-f9c8a32b7ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language_v1\n",
    "\n",
    "client = language_v1.LanguageServiceClient()\n",
    "encoding_type = language_v1.EncodingType.UTF8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92ce11ee-0219-4c0e-bd6e-0014aabd59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.v1 import bigquery as gcc_bq\n",
    "\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import component\n",
    "import google.cloud.aiplatform as aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d7ce031-1a7b-42af-85bb-267d5606d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256955e1-664c-4570-99a3-56524d64c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components.v1.batch_predict_job import ModelBatchPredictOp\n",
    "from google_cloud_pipeline_components.v1.model import ModelUploadOp as model_upload_op\n",
    "from kfp.v2.components import importer_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "990f39b2-fa92-4fac-9397-767daf5c1978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea97afe0-ad3e-40e4-9532-54331f2f4e60",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import data for previous two hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2553e289-5483-440f-917e-3a4fa5a2a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = [' 0', ' 1', ' 2', ' 3', ' 4', ' 5', ' 6', ' 7', ' 8', ' 9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a60b692-3572-41df-b8fc-a187a2846ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' 0', ' 1')\n",
      "(' 2', ' 3')\n",
      "(' 4', ' 5')\n",
      "(' 6', ' 7')\n",
      "(' 8', ' 9')\n",
      "('10', '11')\n",
      "('12', '13')\n",
      "('14', '15')\n",
      "('16', '17')\n",
      "('18', '19')\n",
      "('20', '21')\n",
      "('22', '23')\n"
     ]
    }
   ],
   "source": [
    "for pair in zip(hours[: :2], hours[1: :2]):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "037c30b3-52a6-4a02-8e24-c4257406f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(hour_pair):\n",
    "\n",
    "    query =f\"\"\"\n",
    "    SELECT \n",
    "    *\n",
    "\n",
    "    FROM `curious-skyline-360213.CX.CX_Data_{pair[0].replace(' ','0')}`\n",
    "\n",
    "    \"\"\"\n",
    "    query_job = bq_client.query(query,\n",
    "        #location=\"us-west1\",\n",
    "    )\n",
    "\n",
    "    df_a = query_job.to_dataframe()\n",
    "\n",
    "\n",
    "\n",
    "    query =f\"\"\"\n",
    "    SELECT \n",
    "    *\n",
    "\n",
    "    FROM `curious-skyline-360213.CX.CX_Data_{pair[1].replace(' ','0')}`\n",
    "\n",
    "    \"\"\"\n",
    "    query_job = bq_client.query(query,\n",
    "        #location=\"us-west1\",\n",
    "    )\n",
    "\n",
    "    df_b = query_job.to_dataframe()\n",
    "    \n",
    "\n",
    "    return df_a.append(df_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1ee48a04-438c-4181-b2ac-fd801e69975d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Market</th>\n",
       "      <th>Ministry</th>\n",
       "      <th>Department</th>\n",
       "      <th>Type_Of_Visit</th>\n",
       "      <th>Survey_Completion_Date</th>\n",
       "      <th>Survey_Type</th>\n",
       "      <th>Survey_Project</th>\n",
       "      <th>Survey_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age_Group</th>\n",
       "      <th>LTR_Facility</th>\n",
       "      <th>LTR_Doctor</th>\n",
       "      <th>Anything_Outstanding</th>\n",
       "      <th>Improve_Stay</th>\n",
       "      <th>publish_hour_UTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TX</td>\n",
       "      <td>MIDET</td>\n",
       "      <td>28308</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>HCAHPS</td>\n",
       "      <td>18590</td>\n",
       "      <td>22148</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Awarded as recounting their personal opinions ...</td>\n",
       "      <td>Brought high (Ellis, 2007, p. 4). Relational e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TN</td>\n",
       "      <td>MIDET</td>\n",
       "      <td>25540</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>AMG</td>\n",
       "      <td>17610</td>\n",
       "      <td>16793</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Races 1.7% prove useful</td>\n",
       "      <td>From âˆ’9 of residual heat from the Greek</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MI</td>\n",
       "      <td>TNNAS</td>\n",
       "      <td>13285</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>AMG</td>\n",
       "      <td>29275</td>\n",
       "      <td>17373</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>To newly-built missions which the lithosphere ...</td>\n",
       "      <td>Lower can about approaches, scientific method ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FL</td>\n",
       "      <td>MIDET</td>\n",
       "      <td>12688</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>ED</td>\n",
       "      <td>24403</td>\n",
       "      <td>27074</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>When taken highly specialized. Peer review doe...</td>\n",
       "      <td>Elsewhere across anticipated events</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TX</td>\n",
       "      <td>TNNAS</td>\n",
       "      <td>14117</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>OAS</td>\n",
       "      <td>18980</td>\n",
       "      <td>20761</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Election with of robots' limbs. It would be in...</td>\n",
       "      <td>Amsterdam: Nijgh 2.0%. Hispanics</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>MI</td>\n",
       "      <td>FLJAC</td>\n",
       "      <td>23713</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>ED</td>\n",
       "      <td>14736</td>\n",
       "      <td>29060</td>\n",
       "      <td>Female</td>\n",
       "      <td>35-39</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Faking the year. Lori Ann Wagner, a psychother...</td>\n",
       "      <td>Of communist networks represented, along with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>TN</td>\n",
       "      <td>TXAUS</td>\n",
       "      <td>12121</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>HCAHPS</td>\n",
       "      <td>15496</td>\n",
       "      <td>14659</td>\n",
       "      <td>Male</td>\n",
       "      <td>35-39</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>Problems. Evolutionary Norfolk. Suffolk, which...</td>\n",
       "      <td>The fifth 1993, which provided for by Law and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>FL</td>\n",
       "      <td>TNNAS</td>\n",
       "      <td>15268</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>AMG</td>\n",
       "      <td>25419</td>\n",
       "      <td>12410</td>\n",
       "      <td>Female</td>\n",
       "      <td>35-39</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>Catalogued over discussed by a young age to he...</td>\n",
       "      <td>Art, exhibited It started when Archduke Franz ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>TN</td>\n",
       "      <td>FLJAC</td>\n",
       "      <td>20505</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>OAS</td>\n",
       "      <td>26318</td>\n",
       "      <td>26797</td>\n",
       "      <td>Female</td>\n",
       "      <td>35-39</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>Placed secession terrorism in Argentina and Br...</td>\n",
       "      <td>Revenue than Francisco, CA: Jossey-Bass. ISBN ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>FL</td>\n",
       "      <td>TNNAS</td>\n",
       "      <td>18799</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>ED</td>\n",
       "      <td>11358</td>\n",
       "      <td>15496</td>\n",
       "      <td>Female</td>\n",
       "      <td>35-39</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>French businesses. attached devices to form</td>\n",
       "      <td>Architect and and Monte AlbÃ¡n.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Market Ministry  Department Type_Of_Visit Survey_Completion_Date  \\\n",
       "0       TX    MIDET       28308     In Person             08-26-2022   \n",
       "1       TN    MIDET       25540     In Person             08-26-2022   \n",
       "2       MI    TNNAS       13285     In Person             08-26-2022   \n",
       "3       FL    MIDET       12688       Virtual             08-26-2022   \n",
       "4       TX    TNNAS       14117       Virtual             08-26-2022   \n",
       "..     ...      ...         ...           ...                    ...   \n",
       "235     MI    FLJAC       23713     In Person             08-26-2022   \n",
       "236     TN    TXAUS       12121     In Person             08-26-2022   \n",
       "237     FL    TNNAS       15268     In Person             08-26-2022   \n",
       "238     TN    FLJAC       20505       Virtual             08-26-2022   \n",
       "239     FL    TNNAS       18799     In Person             08-26-2022   \n",
       "\n",
       "    Survey_Type  Survey_Project  Survey_ID  Gender Age_Group  LTR_Facility  \\\n",
       "0        HCAHPS           18590      22148  Female     18-24             1   \n",
       "1           AMG           17610      16793  Female     18-24             1   \n",
       "2           AMG           29275      17373  Female     18-24             1   \n",
       "3            ED           24403      27074  Female     18-24             1   \n",
       "4           OAS           18980      20761  Female     18-24             1   \n",
       "..          ...             ...        ...     ...       ...           ...   \n",
       "235          ED           14736      29060  Female     35-39            10   \n",
       "236      HCAHPS           15496      14659    Male     35-39            10   \n",
       "237         AMG           25419      12410  Female     35-39            10   \n",
       "238         OAS           26318      26797  Female     35-39            10   \n",
       "239          ED           11358      15496  Female     35-39            10   \n",
       "\n",
       "     LTR_Doctor                               Anything_Outstanding  \\\n",
       "0             2  Awarded as recounting their personal opinions ...   \n",
       "1             3                            Races 1.7% prove useful   \n",
       "2             9  To newly-built missions which the lithosphere ...   \n",
       "3             4  When taken highly specialized. Peer review doe...   \n",
       "4             2  Election with of robots' limbs. It would be in...   \n",
       "..          ...                                                ...   \n",
       "235           2  Faking the year. Lori Ann Wagner, a psychother...   \n",
       "236           9  Problems. Evolutionary Norfolk. Suffolk, which...   \n",
       "237           6  Catalogued over discussed by a young age to he...   \n",
       "238           6  Placed secession terrorism in Argentina and Br...   \n",
       "239           1        French businesses. attached devices to form   \n",
       "\n",
       "                                          Improve_Stay publish_hour_UTC  \n",
       "0    Brought high (Ellis, 2007, p. 4). Relational e...                0  \n",
       "1              From âˆ’9 of residual heat from the Greek                0  \n",
       "2    Lower can about approaches, scientific method ...                0  \n",
       "3                  Elsewhere across anticipated events                0  \n",
       "4                     Amsterdam: Nijgh 2.0%. Hispanics                0  \n",
       "..                                                 ...              ...  \n",
       "235  Of communist networks represented, along with ...                0  \n",
       "236  The fifth 1993, which provided for by Law and ...                0  \n",
       "237  Art, exhibited It started when Archduke Franz ...                0  \n",
       "238  Revenue than Francisco, CA: Jossey-Bass. ISBN ...                0  \n",
       "239                     Architect and and Monte AlbÃ¡n.                0  \n",
       "\n",
       "[240 rows x 15 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = load_data((' 0', ' 1'))\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40211119-72b2-48b2-a1a0-97ffa624c2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240 entries, 0 to 239\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Market                  240 non-null    object\n",
      " 1   Ministry                240 non-null    object\n",
      " 2   Department              240 non-null    int64 \n",
      " 3   Type_Of_Visit           240 non-null    object\n",
      " 4   Survey_Completion_Date  240 non-null    object\n",
      " 5   Survey_Type             240 non-null    object\n",
      " 6   Survey_Project          240 non-null    int64 \n",
      " 7   Survey_ID               240 non-null    int64 \n",
      " 8   Gender                  240 non-null    object\n",
      " 9   Age_Group               240 non-null    object\n",
      " 10  LTR_Facility            240 non-null    int64 \n",
      " 11  LTR_Doctor              240 non-null    int64 \n",
      " 12  Anything_Outstanding    240 non-null    object\n",
      " 13  Improve_Stay            240 non-null    object\n",
      " 14  publish_hour_UTC        240 non-null    object\n",
      "dtypes: int64(5), object(10)\n",
      "memory usage: 28.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36936bcf-b101-4568-868c-22481b4768a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_sentiment(comment):\n",
    "    \"\"\"\n",
    "    Returns .Sentiment response from API call \n",
    "    \"\"\"\n",
    "    \n",
    "    if comment is not None:\n",
    "        return client.analyze_sentiment(request = {'document': language_v1.Document(content=comment, type_=language_v1.Document.Type.PLAIN_TEXT, language='en')}).document_sentiment\n",
    "    else:\n",
    "        return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9e4db59-f3c0-4fcb-8100-1bc394d45850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_frames(split_frames):\n",
    "    \n",
    "    df_ = split_frames[0]\n",
    "    for frame in split_frames[1:]:\n",
    "        df_ = df_.append(frame)\n",
    "        \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ca52088-3af5-44be-9995-9d97d8690b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(response):\n",
    "    if response is not np.nan:\n",
    "        return response.score\n",
    "    else:\n",
    "        return response\n",
    "\n",
    "def get_sentiment_magnitude(response):\n",
    "    if response is not np.nan:\n",
    "        return response.magnitude\n",
    "    else:\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c32c4133-a6ff-405d-9945-7c6ffc2b9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_sentiment(df, target_column, chunk_size=599):\n",
    "    \"\"\"\n",
    "    df = data\n",
    "    target_column = df[target_column] containing text to analyze\n",
    "    chunk_size = number of requests per API call with 600/minute being the current maximum\n",
    "    \"\"\"\n",
    "    \n",
    "    #Consider only records containing comments\n",
    "    df_ = df[~df[target_column].isna()]\n",
    "    \n",
    "    #Split data into chunks\n",
    "    chunks_ = 1 + int(len(df_)/chunk_size)\n",
    "    split_frames = np.array_split(df_, chunks_)\n",
    "    \n",
    "    #Make API call\n",
    "    count = 1\n",
    "    for frame in split_frames:\n",
    "        t1=time.time()\n",
    "        frame[f'{target_column}_sentiment'] = frame[f'{target_column}'].apply(lambda z: get_doc_sentiment(z))\n",
    "        t2 = time.time()\n",
    "        \n",
    "        #No need to sleep when no more chunks to analyze\n",
    "        sleep_time=60\n",
    "        if count < chunks_:\n",
    "            print(f'Completed {count} of {chunks_} in {(t2-t1):.1f}s.  Waiting for {int(sleep_time)} sec.')\n",
    "            time.sleep(sleep_time)    \n",
    "            count += 1\n",
    "        \n",
    "        if count == chunks_:\n",
    "            print(f'Completed {count} of {chunks_} in {(t2-t1):.1f}s.')\n",
    "           \n",
    "        \n",
    "        \n",
    "    #Join subset of frames with API response onto the original data\n",
    "    df_result = df.merge(combine_frames(split_frames)[f'{target_column}_sentiment'], left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    df_result[f'{target_column}_sentiment_score'] = df_result[f'{target_column}_sentiment'].apply(lambda z: get_sentiment_score(z))\n",
    "    df_result[f'{target_column}_sentiment_magnitude'] = df_result[f'{target_column}_sentiment'].apply(lambda z: get_sentiment_magnitude(z))\n",
    "    \n",
    "    return df_result.drop(f'{target_column}_sentiment', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "95030249-1e1d-49b4-b373-fb5926eb0bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1 of 1 in 11.6s.\n"
     ]
    }
   ],
   "source": [
    "df_data_sentiment = get_overall_sentiment(df_data, 'Anything_Outstanding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "867ce6af-db6a-4183-9093-94484732b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1 of 1 in 11.7s.\n"
     ]
    }
   ],
   "source": [
    "df_data_sentiment = get_overall_sentiment(df_data_sentiment, 'Improve_Stay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4d0fba05-4380-4e23-b62e-af69c51a88d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Market</th>\n",
       "      <th>Ministry</th>\n",
       "      <th>Department</th>\n",
       "      <th>Type_Of_Visit</th>\n",
       "      <th>Survey_Completion_Date</th>\n",
       "      <th>Survey_Type</th>\n",
       "      <th>Survey_Project</th>\n",
       "      <th>Survey_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age_Group</th>\n",
       "      <th>LTR_Facility</th>\n",
       "      <th>LTR_Doctor</th>\n",
       "      <th>Anything_Outstanding</th>\n",
       "      <th>Improve_Stay</th>\n",
       "      <th>publish_hour_UTC</th>\n",
       "      <th>Anything_Outstanding_sentiment_score</th>\n",
       "      <th>Anything_Outstanding_sentiment_magnitude</th>\n",
       "      <th>Improve_Stay_sentiment_score</th>\n",
       "      <th>Improve_Stay_sentiment_magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TX</td>\n",
       "      <td>MIDET</td>\n",
       "      <td>28308</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>HCAHPS</td>\n",
       "      <td>18590</td>\n",
       "      <td>22148</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Awarded as recounting their personal opinions ...</td>\n",
       "      <td>Brought high (Ellis, 2007, p. 4). Relational e...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TN</td>\n",
       "      <td>MIDET</td>\n",
       "      <td>25540</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>AMG</td>\n",
       "      <td>17610</td>\n",
       "      <td>16793</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Races 1.7% prove useful</td>\n",
       "      <td>From âˆ’9 of residual heat from the Greek</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MI</td>\n",
       "      <td>TNNAS</td>\n",
       "      <td>13285</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>AMG</td>\n",
       "      <td>29275</td>\n",
       "      <td>17373</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>To newly-built missions which the lithosphere ...</td>\n",
       "      <td>Lower can about approaches, scientific method ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FL</td>\n",
       "      <td>MIDET</td>\n",
       "      <td>12688</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>ED</td>\n",
       "      <td>24403</td>\n",
       "      <td>27074</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>When taken highly specialized. Peer review doe...</td>\n",
       "      <td>Elsewhere across anticipated events</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TX</td>\n",
       "      <td>TNNAS</td>\n",
       "      <td>14117</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>OAS</td>\n",
       "      <td>18980</td>\n",
       "      <td>20761</td>\n",
       "      <td>Female</td>\n",
       "      <td>18-24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Election with of robots' limbs. It would be in...</td>\n",
       "      <td>Amsterdam: Nijgh 2.0%. Hispanics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>MI</td>\n",
       "      <td>FLJAC</td>\n",
       "      <td>23713</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>ED</td>\n",
       "      <td>14736</td>\n",
       "      <td>29060</td>\n",
       "      <td>Female</td>\n",
       "      <td>35-39</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Faking the year. Lori Ann Wagner, a psychother...</td>\n",
       "      <td>Of communist networks represented, along with ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>TN</td>\n",
       "      <td>TXAUS</td>\n",
       "      <td>12121</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>HCAHPS</td>\n",
       "      <td>15496</td>\n",
       "      <td>14659</td>\n",
       "      <td>Male</td>\n",
       "      <td>35-39</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>Problems. Evolutionary Norfolk. Suffolk, which...</td>\n",
       "      <td>The fifth 1993, which provided for by Law and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>FL</td>\n",
       "      <td>TNNAS</td>\n",
       "      <td>15268</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>AMG</td>\n",
       "      <td>25419</td>\n",
       "      <td>12410</td>\n",
       "      <td>Female</td>\n",
       "      <td>35-39</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>Catalogued over discussed by a young age to he...</td>\n",
       "      <td>Art, exhibited It started when Archduke Franz ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>TN</td>\n",
       "      <td>FLJAC</td>\n",
       "      <td>20505</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>OAS</td>\n",
       "      <td>26318</td>\n",
       "      <td>26797</td>\n",
       "      <td>Female</td>\n",
       "      <td>35-39</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>Placed secession terrorism in Argentina and Br...</td>\n",
       "      <td>Revenue than Francisco, CA: Jossey-Bass. ISBN ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>FL</td>\n",
       "      <td>TNNAS</td>\n",
       "      <td>18799</td>\n",
       "      <td>In Person</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>ED</td>\n",
       "      <td>11358</td>\n",
       "      <td>15496</td>\n",
       "      <td>Female</td>\n",
       "      <td>35-39</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>French businesses. attached devices to form</td>\n",
       "      <td>Architect and and Monte AlbÃ¡n.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Market Ministry  Department Type_Of_Visit Survey_Completion_Date  \\\n",
       "0       TX    MIDET       28308     In Person             08-26-2022   \n",
       "1       TN    MIDET       25540     In Person             08-26-2022   \n",
       "2       MI    TNNAS       13285     In Person             08-26-2022   \n",
       "3       FL    MIDET       12688       Virtual             08-26-2022   \n",
       "4       TX    TNNAS       14117       Virtual             08-26-2022   \n",
       "..     ...      ...         ...           ...                    ...   \n",
       "235     MI    FLJAC       23713     In Person             08-26-2022   \n",
       "236     TN    TXAUS       12121     In Person             08-26-2022   \n",
       "237     FL    TNNAS       15268     In Person             08-26-2022   \n",
       "238     TN    FLJAC       20505       Virtual             08-26-2022   \n",
       "239     FL    TNNAS       18799     In Person             08-26-2022   \n",
       "\n",
       "    Survey_Type  Survey_Project  Survey_ID  Gender Age_Group  LTR_Facility  \\\n",
       "0        HCAHPS           18590      22148  Female     18-24             1   \n",
       "1           AMG           17610      16793  Female     18-24             1   \n",
       "2           AMG           29275      17373  Female     18-24             1   \n",
       "3            ED           24403      27074  Female     18-24             1   \n",
       "4           OAS           18980      20761  Female     18-24             1   \n",
       "..          ...             ...        ...     ...       ...           ...   \n",
       "235          ED           14736      29060  Female     35-39            10   \n",
       "236      HCAHPS           15496      14659    Male     35-39            10   \n",
       "237         AMG           25419      12410  Female     35-39            10   \n",
       "238         OAS           26318      26797  Female     35-39            10   \n",
       "239          ED           11358      15496  Female     35-39            10   \n",
       "\n",
       "     LTR_Doctor                               Anything_Outstanding  \\\n",
       "0             2  Awarded as recounting their personal opinions ...   \n",
       "1             3                            Races 1.7% prove useful   \n",
       "2             9  To newly-built missions which the lithosphere ...   \n",
       "3             4  When taken highly specialized. Peer review doe...   \n",
       "4             2  Election with of robots' limbs. It would be in...   \n",
       "..          ...                                                ...   \n",
       "235           2  Faking the year. Lori Ann Wagner, a psychother...   \n",
       "236           9  Problems. Evolutionary Norfolk. Suffolk, which...   \n",
       "237           6  Catalogued over discussed by a young age to he...   \n",
       "238           6  Placed secession terrorism in Argentina and Br...   \n",
       "239           1        French businesses. attached devices to form   \n",
       "\n",
       "                                          Improve_Stay publish_hour_UTC  \\\n",
       "0    Brought high (Ellis, 2007, p. 4). Relational e...                0   \n",
       "1              From âˆ’9 of residual heat from the Greek                0   \n",
       "2    Lower can about approaches, scientific method ...                0   \n",
       "3                  Elsewhere across anticipated events                0   \n",
       "4                     Amsterdam: Nijgh 2.0%. Hispanics                0   \n",
       "..                                                 ...              ...   \n",
       "235  Of communist networks represented, along with ...                0   \n",
       "236  The fifth 1993, which provided for by Law and ...                0   \n",
       "237  Art, exhibited It started when Archduke Franz ...                0   \n",
       "238  Revenue than Francisco, CA: Jossey-Bass. ISBN ...                0   \n",
       "239                     Architect and and Monte AlbÃ¡n.                0   \n",
       "\n",
       "     Anything_Outstanding_sentiment_score  \\\n",
       "0                                    -0.5   \n",
       "1                                     0.6   \n",
       "2                                     0.2   \n",
       "3                                     0.2   \n",
       "4                                     0.0   \n",
       "..                                    ...   \n",
       "235                                   0.0   \n",
       "236                                  -0.1   \n",
       "237                                   0.0   \n",
       "238                                  -0.5   \n",
       "239                                   0.0   \n",
       "\n",
       "     Anything_Outstanding_sentiment_magnitude  Improve_Stay_sentiment_score  \\\n",
       "0                                         0.5                          -0.1   \n",
       "1                                         0.6                           0.0   \n",
       "2                                         0.4                           0.0   \n",
       "3                                         0.5                          -0.3   \n",
       "4                                         0.2                           0.1   \n",
       "..                                        ...                           ...   \n",
       "235                                       0.1                          -0.6   \n",
       "236                                       1.0                           0.1   \n",
       "237                                       0.0                           0.0   \n",
       "238                                       0.5                           0.1   \n",
       "239                                       0.0                           0.0   \n",
       "\n",
       "     Improve_Stay_sentiment_magnitude  \n",
       "0                                 0.2  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 0.3  \n",
       "4                                 0.1  \n",
       "..                                ...  \n",
       "235                               0.6  \n",
       "236                               0.1  \n",
       "237                               0.0  \n",
       "238                               0.4  \n",
       "239                               0.0  \n",
       "\n",
       "[240 rows x 19 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b190c22-3976-43e7-b0ee-be81ba9c5dc1",
   "metadata": {},
   "source": [
    "## Turn into a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cfe67c42-10ec-4567-a7a3-3d2f7ef4479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(#output_component_file=\"NLP_sentiment.yaml\", \n",
    "           base_image=\"python:3.7\",\n",
    "           packages_to_install = [\"google-cloud-language\", \n",
    "                                  \"pandas\", \n",
    "                                  \"db-dtypes\", \n",
    "                                  \"google-cloud-bigquery\", \n",
    "                                  \"google-cloud-aiplatform\", \n",
    "                                  \"datetime\", \n",
    "                                  \"fsspec\", \n",
    "                                  \"gcsfs\"]\n",
    "          )\n",
    "\n",
    "def get_overall_sentiment(hour_pair:list, target_column:str, chunk_size:int=599):\n",
    "\n",
    "    project_id = \"curious-skyline-360213\"\n",
    "    \n",
    "    ### Imports ###\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    from google.cloud import language_v1\n",
    "    nlp_client = language_v1.LanguageServiceClient()\n",
    "    encoding_type = language_v1.EncodingType.UTF8\n",
    "    \n",
    "    from google.cloud import bigquery\n",
    "    bq_client = bigquery.Client(location=\"us-west1\", project=project_id)\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "   \n",
    "    ### Helper functions ###\n",
    "    def load_data_from_bq(hour_pair):\n",
    "        query =f\"\"\"\n",
    "        SELECT \n",
    "        *\n",
    "        FROM `curious-skyline-360213.CX.CX_Data_{hour_pair[0].replace(' ','0')}`\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT \n",
    "        *\n",
    "        FROM `curious-skyline-360213.CX.CX_Data_{hour_pair[1].replace(' ','0')}`\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        query_job = bq_client.query(query,\n",
    "                                    #location=\"us-west1\",\n",
    "                                    )\n",
    "\n",
    "        return query_job.to_dataframe()\n",
    "\n",
    "    \n",
    "    def get_doc_sentiment(comment):\n",
    "        \"\"\"\n",
    "        Returns .Sentiment response from API call or passes empty comment\n",
    "        \"\"\"\n",
    "        if comment is not None:\n",
    "            return nlp_client.analyze_sentiment(request = {'document': language_v1.Document(content=comment, \n",
    "                                                                                            type_=language_v1.Document.Type.PLAIN_TEXT, \n",
    "                                                                                            language='en')}).document_sentiment\n",
    "        else:\n",
    "            return comment\n",
    "\n",
    "    def combine_frames(split_frames):\n",
    "\n",
    "        df_ = split_frames[0]\n",
    "        for frame in split_frames[1:]:\n",
    "            df_ = df_.append(frame)\n",
    "\n",
    "        return df_\n",
    "\n",
    "    def get_sentiment_score(response):\n",
    "        if response is not np.nan:\n",
    "            return response.score\n",
    "        else:\n",
    "            return response\n",
    "\n",
    "    def get_sentiment_magnitude(response):\n",
    "        if response is not np.nan:\n",
    "            return response.magnitude\n",
    "        else:\n",
    "            return response\n",
    "    \n",
    "    def process_target(df, target_column):\n",
    "        #Consider only records containing comments\n",
    "        df_ = df[~df[target_column].isna()]\n",
    "\n",
    "        #Split data into chunks\n",
    "        chunks_ = 1 + int(len(df_)/chunk_size)\n",
    "        split_frames = np.array_split(df_, chunks_)\n",
    "\n",
    "        #Make API call\n",
    "        count = 1\n",
    "        for frame in split_frames:\n",
    "            t1=time.time()\n",
    "            frame[f'{target_column}_sentiment'] = frame[f'{target_column}'].apply(lambda z: get_doc_sentiment(z))\n",
    "            t2 = time.time()\n",
    "\n",
    "            #No need to sleep when no more chunks to analyze\n",
    "            sleep_time=60\n",
    "            if count < chunks_:\n",
    "                print(f'Completed {count} of {chunks_} in {(t2-t1):.1f}s.  Waiting for {int(sleep_time)} sec.')\n",
    "                time.sleep(sleep_time)    \n",
    "                count += 1\n",
    "\n",
    "            if count == chunks_:\n",
    "                print(f'Completed {count} of {chunks_} in {(t2-t1):.1f}s.')\n",
    "\n",
    "        #Join subset of frames with API response onto the original data\n",
    "        df_result = df.merge(combine_frames(split_frames)[f'{target_column}_sentiment'], left_index=True, right_index=True, how='left')\n",
    "\n",
    "        df_result[f'{target_column}_sentiment_score'] = df_result[f'{target_column}_sentiment'].apply(lambda z: get_sentiment_score(z))\n",
    "        df_result[f'{target_column}_sentiment_magnitude'] = df_result[f'{target_column}_sentiment'].apply(lambda z: get_sentiment_magnitude(z))\n",
    "    \n",
    "        return df_result\n",
    "\n",
    "    def model_selection(df, row, ltr_target):\n",
    "        \"\"\"\n",
    "        Assign model type based on available input.\n",
    "        ltr_target either of ['LTR_Facility'] or ['LTR_Doctor']\n",
    "        \"\"\"\n",
    "        improve_only = [\"Improve_Stay_sentiment_score\", \"Improve_Stay_sentiment_magnitude\"]\n",
    "        outstanding_only = [\"Anything_Outstanding_sentiment_score\", \"Anything_Outstanding_sentiment_magnitude\"]\n",
    "       \n",
    "        def model_selector(row):\n",
    "            #Improve only\n",
    "            if np.all([pd.isna(row[item]) for item in outstanding_only + ltr_target]) & ~np.all([pd.isna(row[item]) for item in improve_only]):\n",
    "                return \"Improve_only\"\n",
    "            \n",
    "            #Outstanding only\n",
    "            elif np.all([pd.isna(row[item]) for item in improve_only + ltr_target]) & ~np.all([pd.isna(row[item]) for item in outstanding_only]):\n",
    "                return \"Outstanding_only\"\n",
    "        \n",
    "            #All comments\n",
    "            elif np.all([pd.isna(row[item]) for item in ltr_target]) & ~np.all([pd.isna(row[item]) for item in improve_only+outstanding_only]):\n",
    "                return \"Comments_only\"\n",
    "        \n",
    "            #All comments + rating\n",
    "            elif ~np.all([pd.isna(row[item]) for item in improve_only+outstanding_only+ltr_target]):\n",
    "                return \"Comments_and_LTR\"\n",
    "        \n",
    "            #Improve and rating\n",
    "            elif np.all([pd.isna(row[item]) for item in outstanding_only]) & ~np.all([pd.isna(row[item]) for item in improve_only+ltr_target]):\n",
    "                return \"Improve_and_LTR\"\n",
    "        \n",
    "            #Outstanding and rating\n",
    "            elif np.all([pd.isna(row[item]) for item in improve_only]) & ~np.all([pd.isna(row[item]) for item in outstanding_only+ltr_target]):\n",
    "                return \"Outstanding_and_LTR\"\n",
    "        \n",
    "            else:\n",
    "                return \"Model_selection_error\"\n",
    "            \n",
    "        return model_selector(row)\n",
    "\n",
    "    \n",
    "    def predict_tabular_regression_sample(\n",
    "        endpoint_name: str,\n",
    "        instances: List[Dict],\n",
    "        location: str = 'us-west1',\n",
    "        project: str = \"348611359036\"\n",
    "        ):\n",
    "    \n",
    "        aiplatform.init(project=project, location=location)\n",
    "        endpoint = aiplatform.Endpoint(endpoint_name)\n",
    "        result = endpoint.predict(instances=instances)\n",
    "\n",
    "        return result.predictions[0]['value']\n",
    "\n",
    "\n",
    "    #Need a dictionary for endpoints and model_selection to select the right model endpoint based on available data.\n",
    "    Facility_Model_Endpoint_Select = {\"Comments_and_LTR\": \"143006880355057664\"}\n",
    "    Facility_Model_Columns_Select = {\"Comments_and_LTR\": ['Anything_Outstanding_sentiment_score', \n",
    "                                                                 'Anything_Outstanding_sentiment_magnitude', \n",
    "                                                                 'Improve_Stay_sentiment_score', \n",
    "                                                                 'Improve_Stay_sentiment_magnitude', \n",
    "                                                                 'LTR_Doctor']}\n",
    "    \n",
    "    \n",
    "    Doctor_Model_Endpoint_Select = {\"Comments_and_LTR\" : \"1189530843765276672\"}\n",
    "    Doctor_Model_Columns_Select = {\"Comments_and_LTR\": ['Anything_Outstanding_sentiment_score', \n",
    "                                                                 'Anything_Outstanding_sentiment_magnitude', \n",
    "                                                                 'Improve_Stay_sentiment_score', \n",
    "                                                                 'Improve_Stay_sentiment_magnitude', \n",
    "                                                                 'LTR_Facility']}\n",
    "\n",
    "\n",
    "    def generate_instance(model_select, df_row, target):\n",
    "        if target == 'Doctor':\n",
    "            return dict(zip(Doctor_Model_Columns_Select[model_select], [item for item in df_row]) )\n",
    "        else:\n",
    "            return dict(zip(Facility_Model_Columns_Select[model_select], [item for item in df_row]) )\n",
    "\n",
    "\n",
    "    def assign_status(value):\n",
    "        \n",
    "        if value >= 9:\n",
    "            return \"Promoter\"\n",
    "        elif 7<= value <=8:\n",
    "            return \"Neutral\"\n",
    "        else:\n",
    "            return \"Detractor\"\n",
    "    \n",
    "        \n",
    "    \n",
    "    ### MAIN ###    \n",
    "    \n",
    "    #Process first set of comments\n",
    "    df_result_AO = process_target(load_data_from_bq(hour_pair), \"Anything_Outstanding\")\n",
    "    \n",
    "    #Need to sleep, because process_target does not sleep on last run\n",
    "    time.sleep(60)\n",
    "    \n",
    "    #Process second set of comments\n",
    "    df_result = process_target(df_result_AO, \"Improve_Stay\")\n",
    "    \n",
    "    #Drop API response\n",
    "    df_result.drop([\"Anything_Outstanding_sentiment\", \"Improve_Stay_sentiment\"], axis=1, inplace=True)\n",
    "    \n",
    "    #Model selection\n",
    "    df_result['Facility_Model'] = df_result.apply(lambda z: model_selection(df_result, z, [\"LTR_Facility\"]), axis=1)\n",
    "    df_result['Doctor_Model'] = df_result.apply(lambda z: model_selection(df_result, z, [\"LTR_Doctor\"]), axis=1)\n",
    "    \n",
    "    ### Assign P/N/D Status on survey data ###\n",
    "    df_result['LTR_Doctor_Status'] = df_result['LTR_Doctor'].apply(lambda z: assign_status(z))\n",
    "    df_result['LTR_Facility_Status'] = df_result['LTR_Facility'].apply(lambda z: assign_status(z))\n",
    "    \n",
    "    #For some reason model treats this as a string, rather than integer\n",
    "    df_result['LTR_Facility'] = df_result['LTR_Facility'].apply(lambda z: str(z))\n",
    "    df_result['LTR_Doctor'] = df_result['LTR_Doctor'].apply(lambda z: str(z))\n",
    "    \n",
    "    ### Prediction ###\n",
    "    ### Serve prediction\n",
    "    df_result['Facility_Instance'] = df_result.apply(lambda z: generate_instance(z['Facility_Model'], z[Facility_Model_Columns_Select[z['Facility_Model']]], 'Facility'), axis=1)\n",
    "    df_result['Predict_LTR_Facility'] = df_result.apply(lambda z: predict_tabular_regression_sample(endpoint_name=Facility_Model_Endpoint_Select[z['Facility_Model']], instances=[z['Facility_Instance']] ), axis=1)\n",
    "      \n",
    "    df_result['Doctor_Instance'] = df_result.apply(lambda z: generate_instance(z['Doctor_Model'], z[Doctor_Model_Columns_Select[z['Doctor_Model']]], 'Doctor'), axis=1)\n",
    "    df_result['Predict_LTR_Doctor'] = df_result.apply(lambda z: predict_tabular_regression_sample(endpoint_name=Doctor_Model_Endpoint_Select[z['Doctor_Model']], instances=[z['Doctor_Instance']] ), axis=1)\n",
    "    \n",
    "    df_result.drop(['Facility_Instance', 'Doctor_Instance'], axis=1, inplace=True)\n",
    "\n",
    "    ### Assign P/N/D Status on predictions ###\n",
    "    df_result['Predict_LTR_Doctor_Status'] = df_result['Predict_LTR_Doctor'].apply(lambda z: assign_status(z))\n",
    "    df_result['Predict_LTR_Facility_Status'] = df_result['Predict_LTR_Facility'].apply(lambda z: assign_status(z))\n",
    "    \n",
    "    \n",
    "    #Write result to BQ        \n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "    # # Specify a (partial) schema. All columns are always written to the\n",
    "    # # table. The schema is used to assist in data type definitions.\n",
    "    # schema=[\n",
    "    #     # Specify the type of columns whose type cannot be auto-detected. For\n",
    "    #     # example the \"title\" column uses pandas dtype \"object\", so its\n",
    "    #     # data type is ambiguous.\n",
    "    #     bigquery.SchemaField(\"title\", bigquery.enums.SqlTypeNames.STRING),\n",
    "    #     # Indexes are written if included in the schema by name.\n",
    "    #     bigquery.SchemaField(\"wikidata_id\", bigquery.enums.SqlTypeNames.STRING),\n",
    "    # ],\n",
    "    # Optionally, set the write disposition. BigQuery appends loaded rows\n",
    "    # to an existing table by default, but with WRITE_TRUNCATE write\n",
    "    # disposition it replaces the table with the loaded data.\n",
    "    write_disposition='WRITE_APPEND',\n",
    "    # time_partitioning = {\n",
    "    #                     \"type\":\"HOUR\",\n",
    "    #                     \"field\":\"publish_time\"\n",
    "    #                     },\n",
    "    time_partitioning = bigquery.TimePartitioning(type_=bigquery.TimePartitioningType.HOUR, field='publish_time')\n",
    "    )\n",
    "    \n",
    "    table_ref = bigquery.TableReference(dataset_ref=bigquery.DatasetReference(project=project_id, dataset_id='CX'), table_id='CX_Stream_hour_partition_processed')\n",
    "    job = bq_client.load_table_from_dataframe(dataframe=df_result, \n",
    "                                              destination=table_ref, \n",
    "                                              job_config=job_config\n",
    "                                             )\n",
    "    job.result()  # Wait for the job to complete.\n",
    "\n",
    "    table = bq_client.get_table(table_ref)  # Make an API request.\n",
    "    print('Loaded {} rows and {} columns to {}'.format(table.num_rows, len(table.schema), table_ref))    \n",
    "    \n",
    "    ### Save to bucket as .csv for further processing\n",
    "    df_result.to_csv(f\"gs://curious-skyline/Projects/CX/CXpipeline/ProcessedData/{TIMESTAMP[:8]}/{hour_pair[0].replace(' ','0')}{hour_pair[1].replace(' ','0')}/{hour_pair[0].replace(' ','0')}{hour_pair[1].replace(' ','0')}_{TIMESTAMP[:8]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1cfeaa7-f8ea-483e-88f5-fab723e8b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(#output_component_file=\"NLP_sentiment.yaml\", \n",
    "           base_image=\"python:3.7\",\n",
    "           packages_to_install = [\n",
    "                                  \"pandas\", \n",
    "                                  \"db-dtypes\", \n",
    "                                  \"google-cloud-bigquery\", \n",
    "                                  \"google-cloud-aiplatform\", \n",
    "                                  \"datetime\", \n",
    "                                  \"fsspec\", \n",
    "                                  \"gcsfs\",\n",
    "           ])\n",
    "\n",
    "def topic_modeling(hour_pair:list):\n",
    "\n",
    "    project_id = \"curious-skyline-360213\"\n",
    "    \n",
    "    ### Imports ###\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "     \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "   \n",
    "    from google.cloud import aiplatform\n",
    " \n",
    "    ### Helper functions ###\n",
    "    \n",
    "    \n",
    "    ### Load most recently created, processed hour pair data\n",
    "    df_data = pd.read_csv(f\"gs://curious-skyline/Projects/CX/CXpipeline/ProcessedData/{TIMESTAMP[:8]}/{hour_pair[0].replace(' ','0')}{hour_pair[1].replace(' ','0')}_{TIMESTAMP[:8]}.csv\")\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40ce7959-ddd3-422b-a6c6-f5d5d0e4e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"gs://curious-skyline/Projects/CX/CXpipeline/ProcessedData/0001_20220907185538\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "028b5335-0017-44aa-8e31-14c924112e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Market</th>\n",
       "      <th>Ministry</th>\n",
       "      <th>Department</th>\n",
       "      <th>Type_Of_Visit</th>\n",
       "      <th>Survey_Completion_Date</th>\n",
       "      <th>Survey_Type</th>\n",
       "      <th>Survey_Project</th>\n",
       "      <th>Survey_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>...</th>\n",
       "      <th>Improve_Stay_sentiment_score</th>\n",
       "      <th>Improve_Stay_sentiment_magnitude</th>\n",
       "      <th>Facility_Model</th>\n",
       "      <th>Doctor_Model</th>\n",
       "      <th>LTR_Doctor_Status</th>\n",
       "      <th>LTR_Facility_Status</th>\n",
       "      <th>Predict_LTR_Facility</th>\n",
       "      <th>Predict_LTR_Doctor</th>\n",
       "      <th>Predict_LTR_Doctor_Status</th>\n",
       "      <th>Predict_LTR_Facility_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "      <td>TXAUS</td>\n",
       "      <td>22884</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>HCAHPS</td>\n",
       "      <td>14201</td>\n",
       "      <td>22379</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>4.707859</td>\n",
       "      <td>5.866497</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MI</td>\n",
       "      <td>TNNAS</td>\n",
       "      <td>26089</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>HCAHPS</td>\n",
       "      <td>11027</td>\n",
       "      <td>15600</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>4.793215</td>\n",
       "      <td>5.167792</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TX</td>\n",
       "      <td>FLJAC</td>\n",
       "      <td>15936</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>HCAHPS</td>\n",
       "      <td>13852</td>\n",
       "      <td>12294</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>4.897707</td>\n",
       "      <td>5.300736</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MI</td>\n",
       "      <td>MIDET</td>\n",
       "      <td>24274</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>HCAHPS</td>\n",
       "      <td>25211</td>\n",
       "      <td>12925</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>4.906943</td>\n",
       "      <td>6.324744</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TN</td>\n",
       "      <td>FLJAC</td>\n",
       "      <td>27288</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>08-26-2022</td>\n",
       "      <td>ED</td>\n",
       "      <td>11273</td>\n",
       "      <td>12745</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>4.960391</td>\n",
       "      <td>6.141251</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1065</td>\n",
       "      <td>FL</td>\n",
       "      <td>FLJAC</td>\n",
       "      <td>15746</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>ED</td>\n",
       "      <td>22577</td>\n",
       "      <td>21026</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>4.886615</td>\n",
       "      <td>4.992750</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1066</td>\n",
       "      <td>FL</td>\n",
       "      <td>TXAUS</td>\n",
       "      <td>10701</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>ED</td>\n",
       "      <td>15666</td>\n",
       "      <td>25560</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4.952349</td>\n",
       "      <td>5.679932</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>1067</td>\n",
       "      <td>TN</td>\n",
       "      <td>TXAUS</td>\n",
       "      <td>18090</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>ED</td>\n",
       "      <td>22580</td>\n",
       "      <td>22710</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>5.047003</td>\n",
       "      <td>5.260039</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>1068</td>\n",
       "      <td>TN</td>\n",
       "      <td>TNNAS</td>\n",
       "      <td>14968</td>\n",
       "      <td>Virtual</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>OAS</td>\n",
       "      <td>10795</td>\n",
       "      <td>29894</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>4.829739</td>\n",
       "      <td>5.462848</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1069</td>\n",
       "      <td>FL</td>\n",
       "      <td>FLJAC</td>\n",
       "      <td>16764</td>\n",
       "      <td>In Person</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>ED</td>\n",
       "      <td>28297</td>\n",
       "      <td>14560</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Comments_and_LTR</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>4.932217</td>\n",
       "      <td>5.288894</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1070 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Market Ministry  Department Type_Of_Visit  \\\n",
       "0              0     TN    TXAUS       22884       Virtual   \n",
       "1              1     MI    TNNAS       26089       Virtual   \n",
       "2              2     TX    FLJAC       15936       Virtual   \n",
       "3              3     MI    MIDET       24274       Virtual   \n",
       "4              4     TN    FLJAC       27288       Virtual   \n",
       "...          ...    ...      ...         ...           ...   \n",
       "1065        1065     FL    FLJAC       15746       Virtual   \n",
       "1066        1066     FL    TXAUS       10701       Virtual   \n",
       "1067        1067     TN    TXAUS       18090       Virtual   \n",
       "1068        1068     TN    TNNAS       14968       Virtual   \n",
       "1069        1069     FL    FLJAC       16764     In Person   \n",
       "\n",
       "     Survey_Completion_Date Survey_Type  Survey_Project  Survey_ID  Gender  \\\n",
       "0                08-26-2022      HCAHPS           14201      22379    Male   \n",
       "1                08-26-2022      HCAHPS           11027      15600    Male   \n",
       "2                08-26-2022      HCAHPS           13852      12294    Male   \n",
       "3                08-26-2022      HCAHPS           25211      12925    Male   \n",
       "4                08-26-2022          ED           11273      12745  Female   \n",
       "...                     ...         ...             ...        ...     ...   \n",
       "1065             09-02-2022          ED           22577      21026  Female   \n",
       "1066             09-02-2022          ED           15666      25560  Female   \n",
       "1067             09-02-2022          ED           22580      22710  Female   \n",
       "1068             09-02-2022         OAS           10795      29894  Female   \n",
       "1069             09-02-2022          ED           28297      14560  Female   \n",
       "\n",
       "      ... Improve_Stay_sentiment_score  Improve_Stay_sentiment_magnitude  \\\n",
       "0     ...                         -0.7                               0.7   \n",
       "1     ...                         -0.1                               0.1   \n",
       "2     ...                         -0.1                               0.1   \n",
       "3     ...                          0.0                               0.0   \n",
       "4     ...                          0.1                               0.3   \n",
       "...   ...                          ...                               ...   \n",
       "1065  ...                          0.0                               0.0   \n",
       "1066  ...                          0.0                               0.0   \n",
       "1067  ...                          0.1                               0.4   \n",
       "1068  ...                          0.1                               0.1   \n",
       "1069  ...                          0.0                               0.0   \n",
       "\n",
       "        Facility_Model      Doctor_Model LTR_Doctor_Status  \\\n",
       "0     Comments_and_LTR  Comments_and_LTR          Promoter   \n",
       "1     Comments_and_LTR  Comments_and_LTR         Detractor   \n",
       "2     Comments_and_LTR  Comments_and_LTR         Detractor   \n",
       "3     Comments_and_LTR  Comments_and_LTR          Promoter   \n",
       "4     Comments_and_LTR  Comments_and_LTR          Promoter   \n",
       "...                ...               ...               ...   \n",
       "1065  Comments_and_LTR  Comments_and_LTR         Detractor   \n",
       "1066  Comments_and_LTR  Comments_and_LTR         Detractor   \n",
       "1067  Comments_and_LTR  Comments_and_LTR           Neutral   \n",
       "1068  Comments_and_LTR  Comments_and_LTR           Neutral   \n",
       "1069  Comments_and_LTR  Comments_and_LTR         Detractor   \n",
       "\n",
       "     LTR_Facility_Status  Predict_LTR_Facility  Predict_LTR_Doctor  \\\n",
       "0              Detractor              4.707859            5.866497   \n",
       "1              Detractor              4.793215            5.167792   \n",
       "2              Detractor              4.897707            5.300736   \n",
       "3              Detractor              4.906943            6.324744   \n",
       "4              Detractor              4.960391            6.141251   \n",
       "...                  ...                   ...                 ...   \n",
       "1065           Detractor              4.886615            4.992750   \n",
       "1066             Neutral              4.952349            5.679932   \n",
       "1067             Neutral              5.047003            5.260039   \n",
       "1068           Detractor              4.829739            5.462848   \n",
       "1069           Detractor              4.932217            5.288894   \n",
       "\n",
       "      Predict_LTR_Doctor_Status  Predict_LTR_Facility_Status  \n",
       "0                     Detractor                    Detractor  \n",
       "1                     Detractor                    Detractor  \n",
       "2                     Detractor                    Detractor  \n",
       "3                     Detractor                    Detractor  \n",
       "4                     Detractor                    Detractor  \n",
       "...                         ...                          ...  \n",
       "1065                  Detractor                    Detractor  \n",
       "1066                  Detractor                    Detractor  \n",
       "1067                  Detractor                    Detractor  \n",
       "1068                  Detractor                    Detractor  \n",
       "1069                  Detractor                    Detractor  \n",
       "\n",
       "[1070 rows x 29 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9154d47-f290-48ce-a4dc-09f8bd58fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp = df_test.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8d6fd0b-b1bd-421e-934d-e9462af6d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "import gcsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa5c6203-933f-483d-b928-a493411c698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/hrishi-ds/Medium/blob/main/Visualize-Confusion-Matrix-Using-Sankey-Diagram/visualise-confusion-matrix-using-sankey.ipynb\n",
    "\n",
    "def transform_confusion_matrix(cf_matrix_, targets_list=None):\n",
    "    \"\"\"\n",
    "    function to transform confusion matrix to dataframe needed to plot Sankey chart\n",
    "    \n",
    "    returns a dataframe and list of unique labels for Sankey chart nodes\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    cf_matrix_ : numpy.ndarray\n",
    "        The confusion matrix to be visualised\n",
    "    target_list : {'list', 'numpy.ndarray'}\n",
    "        List of unique classes\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # create a dataframe\n",
    "    \n",
    "    if targets_list is None:\n",
    "        df = pd.DataFrame(data=cf_matrix_, \n",
    "                          index=[f\"True Class-{i+1}\" for i in range(cf_matrix_.shape[0])],\n",
    "                          columns=[f\"Predicted Class-{i+1}\" for i in range(cf_matrix_.shape[0])])\n",
    "    else:\n",
    "        df = pd.DataFrame(data=cf_matrix_, \n",
    "                          index=[f\"Rating {i}\" for i in targets_list],\n",
    "                          columns=[f\"Sentiment {i}\" for i in targets_list])\n",
    "\n",
    "    # restructre the dataframe\n",
    "    df = df.stack().reset_index()\n",
    "\n",
    "    # rename the default column names\n",
    "    df.rename(columns={'level_0':'source', 'level_1':'target', 0:'value'}, inplace=True)\n",
    "\n",
    "    # add new column for colour\n",
    "    # here rgba(211,255,216,0.6) indicates green colour whereas rgba(245,173,168,0.6) is red colour\n",
    "    # green colour illustrates correct predictions and red colour is for incorrect predictions\n",
    "    df[\"colour\"] = df.apply(lambda x: \n",
    "                              \"rgba(211,255,216,0.6)\" if x.source.split()[1:] == x.target.split()[1:] \n",
    "                               else \"rgba(245,173,168,0.6)\", axis=1)\n",
    "\n",
    "    # extract unique values from source and target columns\n",
    "    labels = pd.concat([df.source, df.target]).unique()\n",
    "\n",
    "    # get indices of the above unique values\n",
    "    labels_indices = {label:index for index, label in enumerate(labels)}\n",
    "    labels_indices\n",
    "\n",
    "    # map the source and target column using the above indices\n",
    "    df[[\"source\", \"target\"]] = df[[\"source\", \"target\"]].applymap(lambda x: labels_indices[x])\n",
    "\n",
    "    # create a column for tooltip\n",
    "    df[\"tooltip\"] = df.apply(lambda x:\n",
    "                             f\"{x['value']} {' '.join(labels[x['source']].split()[1:])} instances correctly classified as {' '.join(labels[x['target']].split()[1:])}\" \n",
    "                             if x['colour']=='rgba(211,255,216,0.6)'\n",
    "\n",
    "                             else \n",
    "                             f\"{x['value']} {' '.join(labels[x['source']].split()[1:])} instances misclassified as {' '.join(labels[x['target']].split()[1:])}\", axis=1)\n",
    "\n",
    "    return df, labels\n",
    "    \n",
    "\n",
    "def plot_sankey_for_confusion_matrix(df, labels, title):\n",
    "    \n",
    "    \"\"\"\n",
    "    plots sankey diagram from given dataframe and labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # plot figure\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "    \n",
    "    node = dict(\n",
    "      pad = 20,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 1.0),\n",
    "      label = labels,\n",
    "      \n",
    "      # this template will be used to display text when hovering over nodes  \n",
    "      hovertemplate = \"%{label} has total %{value:d} instances<extra></extra>\"\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = df.source, \n",
    "      target = df.target,\n",
    "      value = df.value,\n",
    "      color = df.colour,\n",
    "      customdata = df['tooltip'], \n",
    "        \n",
    "      # this template will be used to display text when hovering over the links  \n",
    "      hovertemplate = \"%{customdata}<extra></extra>\"  \n",
    "    ))])\n",
    "\n",
    "    fig.update_layout(title_text=title, font_size=13,\n",
    "                      width=510, height=450)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8dd83c1b-663d-4bae-844a-e76595d6d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ab6240df-c898-4aa0-a5ea-dea30991be47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(df_nlp['LTR_Doctor_Status'], df_nlp['Predict_LTR_Doctor_Status'])\n",
    "\n",
    "df,labels = transform_confusion_matrix(cf_matrix, ['Detractor', 'Neutral', 'Promoter']) \n",
    "plot_ = plot_sankey_for_confusion_matrix(df, labels, \"LTR Doctor: Rating vs. Feedback Sentiment\")\n",
    "storage.Client(project=project_id).bucket(\"curious-skyline\").blob(f\"Projects/CX/CXpipeline/ProcessedData/{TIMESTAMP[:8]}/{hour_pair[0].replace(' ','0')}{hour_pair[1].replace(' ','0')}/ltr_doctor_clf_snakey.png\").upload_from_string(plot_.to_image(format = 'png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5529bae8-2a6d-4c85-b543-5b07229d21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2e0b745c-3007-4b48-9981-d500571f436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "\n",
    "categories = [\"Detractor\", \"Neutral\", \"Promoter\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(3,3)\n",
    "\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap='Blues', cbar=False, xticklabels=categories, yticklabels=categories )\n",
    "\n",
    "plt.ylabel(\"Patient NPS\")\n",
    "plt.xlabel(\"NLP Predicted NPS\")\n",
    "#plt.savefig(\"ltr_doctor_clf_matrix_.png\")\n",
    "buffer_ = BytesIO()\n",
    "_ = plt.savefig(buffer_, format='png')\n",
    "#Close to prevent display\n",
    "plt.close(fig)\n",
    "storage.Client(project=project_id).bucket(\"curious-skyline\").blob(f\"Projects/CX/CXpipeline/ProcessedData/{TIMESTAMP[:8]}/{hour_pair[0].replace(' ','0')}{hour_pair[1].replace(' ','0')}/ltr_doctor_clf_matrix.png\").upload_from_string(buffer_.getvalue())\n",
    "\n",
    "report = classification_report(df_nlp['LTR_Doctor_Status'], df_nlp['Predict_LTR_Doctor_Status'],  output_dict=True, zero_division=0)\n",
    "report.update({\"accuracy\": {\"precision\": None, \"recall\": None, \"f1-score\": report[\"accuracy\"], \"support\": report['macro avg']['support']}})\n",
    "\n",
    "report_ = pd.DataFrame(report).T\n",
    "#report_.to_csv(\"ltr_doctor_clf_report_.csv\")\n",
    "storage.Client(project=project_id).bucket(\"curious-skyline\").blob(f\"Projects/CX/CXpipeline/ProcessedData/{TIMESTAMP[:8]}/{hour_pair[0].replace(' ','0')}{hour_pair[1].replace(' ','0')}/ltr_doctor_clf_report.csv\").upload_from_string(report_.to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251de0c-3a53-4c53-9879-53b7b76b5372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e880b19c-42aa-47d4-bacb-bb3fc6e25d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1295: FutureWarning:\n",
      "\n",
      "APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "hours = [' 0', ' 1', ' 2', ' 3', ' 4', ' 5', ' 6', ' 7', ' 8', ' 9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n",
    "\n",
    "# create working dir to pass to job spec\n",
    "WORKING_DIR = f\"{pipeline_root_path}/{TIMESTAMP}\"\n",
    "\n",
    "\n",
    "for pair in zip(hours[: :2], hours[1: :2]):\n",
    "    \n",
    "    hour_pair_str = pair[0].replace(' ', '0')+pair[1].replace(' ', '0')\n",
    "    @kfp.dsl.pipeline(\n",
    "        name=f\"cx-pipeline-nlp-sentiment-hours-{hour_pair_str}\",\n",
    "        description=\"NLP sentiment process\",\n",
    "        pipeline_root=pipeline_root_path)\n",
    "\n",
    "    #Move streaming data to hourly table\n",
    "    def pipeline(project_id:str, \n",
    "                 hour_pair:list):\n",
    "                                \n",
    "        #Cloud Natural Language API sentiment score and sentiment magnitude\n",
    "        #Model selection task based on available comments and scores\n",
    "        nlp_sentiment_and_model_selection = get_overall_sentiment(hour_pair, target_column = \"Anything_Outstanding\", chunk_size=599)\n",
    "        \n",
    "        #\n",
    "\n",
    "    compiler.Compiler().compile(\n",
    "        pipeline_func=pipeline,\n",
    "        package_path=f'cx-pipeline-nlp-sentiment-hours-{hour_pair_str}.json'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d900c698-2750-4b8e-bbb8-6f2f4d50ddc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/348611359036/locations/us-central1/pipelineJobs/cx-pipeline-nlp-sentiment-hours-0001-20220907221022\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/348611359036/locations/us-central1/pipelineJobs/cx-pipeline-nlp-sentiment-hours-0001-20220907221022')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/cx-pipeline-nlp-sentiment-hours-0001-20220907221022?project=348611359036\n"
     ]
    }
   ],
   "source": [
    "job = aip.PipelineJob(\n",
    "    display_name=\"cx-pipeline-nlp-sentiment-hours-0001\",\n",
    "    template_path='cx-pipeline-nlp-sentiment-hours-0001.json',\n",
    "    pipeline_root=pipeline_root_path,\n",
    "    parameter_values={\n",
    "        'project_id': project_id,\n",
    "        'hour_pair': [' 0', ' 1']\n",
    "    }\n",
    "   \n",
    ")\n",
    "\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943e668-c5fc-41bc-910d-f1b33e2f5ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
